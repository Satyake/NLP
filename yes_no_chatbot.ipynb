{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yes/no chatbot",
      "provenance": [],
      "authorship_tag": "ABX9TyMzzhbCXcq5JeRm+4+lTqll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyake/NLP/blob/master/yes_no_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg5FZyUJ1FYA"
      },
      "source": [
        "import pickle\r\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsUixALT_nrY"
      },
      "source": [
        "with open('/content/train_qa.txt','rb') as f:\r\n",
        "  train_data=pickle.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRWp0Ti1DCJZ"
      },
      "source": [
        "with open('/content/train_qa.txt','rb') as f:\r\n",
        "  test_data=pickle.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvp-L8Uo_u2h"
      },
      "source": [
        "\r\n",
        "#train_data=np.array(train_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DjtOl9RGkI0"
      },
      "source": [
        "#train_data.shape"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV1CsiygDLqy",
        "outputId": "19b7e928-fbe8-49e1-c46a-3b8d191f3b43"
      },
      "source": [
        "set(train_data[0][0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'journeyed',\n",
              " 'moved',\n",
              " 'the',\n",
              " 'to'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2ccB24tGDWb1",
        "outputId": "47b935c6-cfcf-4d73-c18d-3451cefbec2f"
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f9Kja1lNDa2U",
        "outputId": "085a5f8b-350d-4a0a-9954-b8fd1ca72d70"
      },
      "source": [
        "''.join(train_data[0][2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WROjhBhgDcN6"
      },
      "source": [
        "all_data=test_data+train_data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-c7fBBDfCg",
        "outputId": "c83b5f1b-6df6-4549-91f1-ae4ffac865c0"
      },
      "source": [
        "len(all_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZA62-62Difa"
      },
      "source": [
        "#using set to add words.\r\n",
        "vocab=set()\r\n",
        "for story ,question, answer in all_data:\r\n",
        "  vocab=vocab.union(set(story))\r\n",
        "  vocab=vocab.union(set(question))\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArbvWIr7EEK6"
      },
      "source": [
        "vocab.add('no')\r\n",
        "vocab.add('yes')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_kBnCZ8EMGn"
      },
      "source": [
        "vocab_len=len(vocab)+1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbG4k1jLEVjy"
      },
      "source": [
        "all_story_len=[len(data[0]) for data in all_data]\r\n",
        "all_question_len=[len(data[1]) for data in all_data] "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB8Ht-fHEnb7"
      },
      "source": [
        "max_story_len=max(all_story_len)\r\n",
        "max_question_len=max(all_question_len)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it7ckkUYE08F"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmfOKWW2LaBH"
      },
      "source": [
        "tknizer=Tokenizer(filters=[])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eao4RxBOLdNU"
      },
      "source": [
        "tknizer.fit_on_texts(vocab)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXCcfcjZLjLd",
        "outputId": "1107e5cb-dcda-4900-f64e-4c46b4f89413"
      },
      "source": [
        "tknizer.word_index"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 18,\n",
              " '?': 30,\n",
              " 'apple': 20,\n",
              " 'back': 34,\n",
              " 'bathroom': 2,\n",
              " 'bedroom': 3,\n",
              " 'daniel': 5,\n",
              " 'discarded': 36,\n",
              " 'down': 33,\n",
              " 'dropped': 12,\n",
              " 'football': 10,\n",
              " 'garden': 35,\n",
              " 'got': 6,\n",
              " 'grabbed': 21,\n",
              " 'hallway': 7,\n",
              " 'in': 16,\n",
              " 'is': 22,\n",
              " 'john': 29,\n",
              " 'journeyed': 9,\n",
              " 'kitchen': 32,\n",
              " 'left': 17,\n",
              " 'mary': 1,\n",
              " 'milk': 37,\n",
              " 'moved': 4,\n",
              " 'no': 13,\n",
              " 'office': 31,\n",
              " 'picked': 11,\n",
              " 'put': 27,\n",
              " 'sandra': 8,\n",
              " 'the': 15,\n",
              " 'there': 28,\n",
              " 'to': 26,\n",
              " 'took': 19,\n",
              " 'travelled': 25,\n",
              " 'up': 23,\n",
              " 'went': 14,\n",
              " 'yes': 24}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mew6fMg8LojJ"
      },
      "source": [
        "#perform tokenizing for story question and answer\r\n",
        "train_story_text=[]\r\n",
        "train_question_text=[]\r\n",
        "train_answers=[]\r\n",
        "for story,question,answer in train_data:\r\n",
        "  train_story_text.append(story)\r\n",
        "  train_question_text.append(question)\r\n",
        "  train_answers.append(answer)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAlfSlxEL9xI"
      },
      "source": [
        "train_story_seq=tknizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuHhjPUP4WA9",
        "outputId": "ed10c112-2cc5-4207-ddfe-ad077db7ac4b"
      },
      "source": [
        "pad_sequences(train_story_seq,maxlen=max_story_len)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 15,  3, 18],\n",
              "       [ 0,  0,  0, ..., 15,  7, 18],\n",
              "       [ 0,  0,  0, ..., 15,  2, 18],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 15,  3, 18],\n",
              "       [ 0,  0,  0, ..., 37, 28, 18],\n",
              "       [ 0,  0,  0, ..., 20, 28, 18]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJJ0afm4MD8a",
        "outputId": "a6b75246-2891-4403-9cfe-bb83ea5387eb"
      },
      "source": [
        "max_story_len"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNiMuMvqzjHG"
      },
      "source": [
        "#word_index=tknizer.word_index"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4jILoRNMGDJ"
      },
      "source": [
        "#function for vectorize\r\n",
        "def vectorize_stories(data,word_index=tknizer.word_index,max_story_len=max_story_len,max_question_len=max_question_len):\r\n",
        "  #stories\r\n",
        "  X=[]\r\n",
        "  #questions\r\n",
        "  Xq=[]\r\n",
        "  #answers Y/N\r\n",
        "  Y=[]\r\n",
        "  for story,query,answer in data:\r\n",
        "    x=[word_index[word.lower()] for word in story]\r\n",
        "    xq=[word_index[word.lower()] for word in query]\r\n",
        "    y=np.zeros(len(word_index)+1)\r\n",
        "    y[word_index[answer]]=1\r\n",
        "    X.append(x)\r\n",
        "    Xq.append(xq)\r\n",
        "    Y.append(y)\r\n",
        "  return (pad_sequences(X,maxlen=max_story_len),pad_sequences(Xq,maxlen=max_question_len),np.array(Y))\r\n",
        "\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_au4rln35Se",
        "outputId": "c4101f0d-65dc-4075-f79c-927c9cf94efe"
      },
      "source": [
        "max_question_len"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWjrJSpN0Rg0"
      },
      "source": [
        "inputs_train,queries_train,answers_train=vectorize_stories(train_data)\r\n",
        "inputs_test,queries_test,answers_test=vectorize_stories(test_data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qtqkzp338Ch",
        "outputId": "69e69c1e-1f5a-40ef-d4d2-65adc1a9ba53"
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 15,  3, 18],\n",
              "       [ 0,  0,  0, ..., 15,  7, 18],\n",
              "       [ 0,  0,  0, ..., 15,  2, 18],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 15,  3, 18],\n",
              "       [ 0,  0,  0, ..., 37, 28, 18],\n",
              "       [ 0,  0,  0, ..., 20, 28, 18]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ3q3_9XBi_C",
        "outputId": "62f7b890-1642-4e6b-d0e4-b5445be9ee2a"
      },
      "source": [
        "tknizer.word_index['no']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feavoq9YBrA6"
      },
      "source": [
        "from keras.models import Sequential,Model\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers import Input,Activation,Dense,Permute,Dropout,LSTM,concatenate,dot,add"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z92c7IN_CLsN"
      },
      "source": [
        "#Placeholder shape=(max_story_len,batch_size)\r\n",
        "input_sequence=Input((max_story_len,))\r\n",
        "question=Input((max_question_len,))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlBt-ZGTCrtn"
      },
      "source": [
        "#vocab_len \r\n",
        "vocab_size=len(vocab)+1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZhay9PhDHWh"
      },
      "source": [
        "#Input Encoder M\r\n",
        "input_encoder_m=Sequential()\r\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\r\n",
        "input_encoder_m.add(Dropout(0.5))\r\n",
        "#outputs (samples,story_maxlen,embedding_dim)\r\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdGYJvKADgyG"
      },
      "source": [
        "#Input Encoder C\r\n",
        "input_encoder_c=Sequential()\r\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\r\n",
        "input_encoder_c.add(Dropout(0.5))\r\n",
        "#outputs (samples,story_maxlen,embedding_dim)\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzr311K7DwAR"
      },
      "source": [
        "#Input Encoder Q\r\n",
        "question_encoder=Sequential()\r\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_len))\r\n",
        "question_encoder.add(Dropout(0.5))\r\n",
        "#outputs (samples,story_maxlen,max_question_len)\r\n",
        "\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDLo5fwTF6L5"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg3QGnswEL9M"
      },
      "source": [
        "input_encoded_m=input_encoder_m(input_sequence)\r\n",
        "input_encoded_c=input_encoder_c(input_sequence)\r\n",
        "question_encoded=question_encoder(question)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVNwzljTEi-B"
      },
      "source": [
        "match=dot([input_encoded_m,question_encoded],axes=(2,2))\r\n",
        "match=Activation('softmax')(match)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kK6Z8osD_Qw"
      },
      "source": [
        "response=add([match,input_encoded_c])\r\n",
        "response=Permute((2,1))(response)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8FIHDVSENt7"
      },
      "source": [
        "answer=concatenate([response,question_encoded])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsO5GTcPERWo",
        "outputId": "1393550c-179a-4085-d920-0f4108bc4d83"
      },
      "source": [
        "answer"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd5ypwvkHcQp"
      },
      "source": [
        "answer=LSTM(100)(answer)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjDMzgJ2IcFV",
        "outputId": "88199a61-6958-41db-df43-175e808f0a91"
      },
      "source": [
        "answer"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'lstm')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6J2DuIiEfhP"
      },
      "source": [
        "answer=Dropout(0.5)(answer)\r\n",
        "answer=Dense(vocab_size)(answer)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICn-Mb5EpP2"
      },
      "source": [
        "answer=Activation('softmax')(answer)\r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h8thlU_Esuq"
      },
      "source": [
        "model=Model([input_sequence,question],answer)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEQTSK2_E18o"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQEo95UjFE2n",
        "outputId": "e6653375-eaf5-44fb-a846-33f66c53ec52"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 100)          128400      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 100)          0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 38)           3838        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 137,330\n",
            "Trainable params: 137,330\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6DVsv8yF1PB",
        "outputId": "a18e9eeb-2220-430c-e598-1580fb9ad74c"
      },
      "source": [
        "history=model.fit([inputs_train,queries_train],answers_train,batch_size=64,epochs=100,validation_data=([inputs_test,queries_test],answers_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "157/157 [==============================] - 9s 43ms/step - loss: 1.3465 - accuracy: 0.4637 - val_loss: 0.7008 - val_accuracy: 0.4988\n",
            "Epoch 2/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.7186 - accuracy: 0.4896 - val_loss: 0.6943 - val_accuracy: 0.5012\n",
            "Epoch 3/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.7023 - accuracy: 0.4964 - val_loss: 0.6937 - val_accuracy: 0.4988\n",
            "Epoch 4/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.7002 - accuracy: 0.4881 - val_loss: 0.6963 - val_accuracy: 0.5012\n",
            "Epoch 5/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6967 - accuracy: 0.5008 - val_loss: 0.6936 - val_accuracy: 0.5012\n",
            "Epoch 6/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6957 - accuracy: 0.5077 - val_loss: 0.6945 - val_accuracy: 0.5012\n",
            "Epoch 7/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6975 - accuracy: 0.4919 - val_loss: 0.6996 - val_accuracy: 0.4988\n",
            "Epoch 8/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6970 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
            "Epoch 9/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6960 - accuracy: 0.4952 - val_loss: 0.6952 - val_accuracy: 0.4988\n",
            "Epoch 10/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6966 - accuracy: 0.4974 - val_loss: 0.6934 - val_accuracy: 0.5012\n",
            "Epoch 11/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6949 - accuracy: 0.5073 - val_loss: 0.6933 - val_accuracy: 0.4988\n",
            "Epoch 12/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6944 - accuracy: 0.5106 - val_loss: 0.6943 - val_accuracy: 0.5012\n",
            "Epoch 13/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6955 - accuracy: 0.4933 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
            "Epoch 14/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6937 - accuracy: 0.5070 - val_loss: 0.6963 - val_accuracy: 0.4988\n",
            "Epoch 15/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6957 - accuracy: 0.4958 - val_loss: 0.6942 - val_accuracy: 0.4988\n",
            "Epoch 16/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6943 - accuracy: 0.5119 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
            "Epoch 17/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6961 - accuracy: 0.4988 - val_loss: 0.6939 - val_accuracy: 0.5012\n",
            "Epoch 18/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6966 - accuracy: 0.4889 - val_loss: 0.6932 - val_accuracy: 0.5025\n",
            "Epoch 19/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6952 - accuracy: 0.4947 - val_loss: 0.6933 - val_accuracy: 0.4988\n",
            "Epoch 20/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6950 - accuracy: 0.5042 - val_loss: 0.6977 - val_accuracy: 0.5012\n",
            "Epoch 21/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6955 - accuracy: 0.4990 - val_loss: 0.6933 - val_accuracy: 0.5012\n",
            "Epoch 22/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6945 - accuracy: 0.4964 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
            "Epoch 23/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6958 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5210\n",
            "Epoch 24/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6943 - accuracy: 0.5041 - val_loss: 0.6940 - val_accuracy: 0.4988\n",
            "Epoch 25/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6954 - accuracy: 0.4956 - val_loss: 0.6934 - val_accuracy: 0.4988\n",
            "Epoch 26/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6944 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.5012\n",
            "Epoch 27/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6956 - accuracy: 0.4917 - val_loss: 0.6941 - val_accuracy: 0.4988\n",
            "Epoch 28/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6932 - accuracy: 0.5121 - val_loss: 0.6949 - val_accuracy: 0.5012\n",
            "Epoch 29/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6957 - accuracy: 0.4943 - val_loss: 0.6923 - val_accuracy: 0.5340\n",
            "Epoch 30/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.6917 - accuracy: 0.5231 - val_loss: 0.6808 - val_accuracy: 0.5604\n",
            "Epoch 31/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6503 - accuracy: 0.6021 - val_loss: 0.4324 - val_accuracy: 0.8135\n",
            "Epoch 32/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.4689 - accuracy: 0.7938 - val_loss: 0.3646 - val_accuracy: 0.8405\n",
            "Epoch 33/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.4200 - accuracy: 0.8196 - val_loss: 0.3368 - val_accuracy: 0.8615\n",
            "Epoch 34/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3898 - accuracy: 0.8325 - val_loss: 0.3232 - val_accuracy: 0.8610\n",
            "Epoch 35/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3846 - accuracy: 0.8418 - val_loss: 0.3091 - val_accuracy: 0.8685\n",
            "Epoch 36/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3700 - accuracy: 0.8408 - val_loss: 0.3119 - val_accuracy: 0.8622\n",
            "Epoch 37/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3670 - accuracy: 0.8430 - val_loss: 0.3121 - val_accuracy: 0.8584\n",
            "Epoch 38/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3560 - accuracy: 0.8504 - val_loss: 0.2953 - val_accuracy: 0.8699\n",
            "Epoch 39/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3414 - accuracy: 0.8513 - val_loss: 0.2925 - val_accuracy: 0.8686\n",
            "Epoch 40/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3503 - accuracy: 0.8424 - val_loss: 0.2983 - val_accuracy: 0.8663\n",
            "Epoch 41/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3366 - accuracy: 0.8503 - val_loss: 0.2892 - val_accuracy: 0.8708\n",
            "Epoch 42/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3444 - accuracy: 0.8504 - val_loss: 0.3029 - val_accuracy: 0.8587\n",
            "Epoch 43/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3291 - accuracy: 0.8535 - val_loss: 0.2842 - val_accuracy: 0.8729\n",
            "Epoch 44/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3269 - accuracy: 0.8554 - val_loss: 0.2844 - val_accuracy: 0.8705\n",
            "Epoch 45/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3343 - accuracy: 0.8516 - val_loss: 0.2831 - val_accuracy: 0.8709\n",
            "Epoch 46/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3161 - accuracy: 0.8587 - val_loss: 0.2817 - val_accuracy: 0.8727\n",
            "Epoch 47/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3182 - accuracy: 0.8552 - val_loss: 0.3001 - val_accuracy: 0.8595\n",
            "Epoch 48/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3307 - accuracy: 0.8489 - val_loss: 0.2756 - val_accuracy: 0.8746\n",
            "Epoch 49/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3140 - accuracy: 0.8613 - val_loss: 0.2814 - val_accuracy: 0.8721\n",
            "Epoch 50/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3173 - accuracy: 0.8573 - val_loss: 0.2734 - val_accuracy: 0.8746\n",
            "Epoch 51/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3137 - accuracy: 0.8605 - val_loss: 0.2735 - val_accuracy: 0.8747\n",
            "Epoch 52/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3178 - accuracy: 0.8528 - val_loss: 0.2764 - val_accuracy: 0.8726\n",
            "Epoch 53/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3222 - accuracy: 0.8562 - val_loss: 0.2755 - val_accuracy: 0.8734\n",
            "Epoch 54/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3172 - accuracy: 0.8546 - val_loss: 0.2710 - val_accuracy: 0.8754\n",
            "Epoch 55/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3080 - accuracy: 0.8607 - val_loss: 0.2712 - val_accuracy: 0.8759\n",
            "Epoch 56/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3180 - accuracy: 0.8544 - val_loss: 0.2729 - val_accuracy: 0.8747\n",
            "Epoch 57/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3062 - accuracy: 0.8621 - val_loss: 0.2700 - val_accuracy: 0.8772\n",
            "Epoch 58/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.2982 - accuracy: 0.8691 - val_loss: 0.2715 - val_accuracy: 0.8749\n",
            "Epoch 59/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2887 - accuracy: 0.8743 - val_loss: 0.2702 - val_accuracy: 0.8758\n",
            "Epoch 60/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3033 - accuracy: 0.8657 - val_loss: 0.2699 - val_accuracy: 0.8751\n",
            "Epoch 61/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3085 - accuracy: 0.8623 - val_loss: 0.2682 - val_accuracy: 0.8782\n",
            "Epoch 62/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3051 - accuracy: 0.8610 - val_loss: 0.2691 - val_accuracy: 0.8760\n",
            "Epoch 63/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2973 - accuracy: 0.8684 - val_loss: 0.2678 - val_accuracy: 0.8748\n",
            "Epoch 64/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.2951 - accuracy: 0.8679 - val_loss: 0.2673 - val_accuracy: 0.8781\n",
            "Epoch 65/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.2982 - accuracy: 0.8694 - val_loss: 0.2741 - val_accuracy: 0.8711\n",
            "Epoch 66/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3069 - accuracy: 0.8595 - val_loss: 0.2673 - val_accuracy: 0.8762\n",
            "Epoch 67/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3055 - accuracy: 0.8613 - val_loss: 0.2649 - val_accuracy: 0.8764\n",
            "Epoch 68/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3085 - accuracy: 0.8583 - val_loss: 0.2701 - val_accuracy: 0.8763\n",
            "Epoch 69/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3009 - accuracy: 0.8630 - val_loss: 0.2668 - val_accuracy: 0.8776\n",
            "Epoch 70/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.3050 - accuracy: 0.8591 - val_loss: 0.2669 - val_accuracy: 0.8801\n",
            "Epoch 71/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2979 - accuracy: 0.8646 - val_loss: 0.2605 - val_accuracy: 0.8822\n",
            "Epoch 72/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2979 - accuracy: 0.8613 - val_loss: 0.2622 - val_accuracy: 0.8786\n",
            "Epoch 73/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2937 - accuracy: 0.8686 - val_loss: 0.2633 - val_accuracy: 0.8821\n",
            "Epoch 74/100\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3029 - accuracy: 0.8626 - val_loss: 0.2639 - val_accuracy: 0.8804\n",
            "Epoch 75/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2968 - accuracy: 0.8641 - val_loss: 0.2648 - val_accuracy: 0.8772\n",
            "Epoch 76/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2997 - accuracy: 0.8633 - val_loss: 0.2591 - val_accuracy: 0.8822\n",
            "Epoch 77/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2933 - accuracy: 0.8641 - val_loss: 0.2631 - val_accuracy: 0.8785\n",
            "Epoch 78/100\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.2965 - accuracy: 0.8704 - val_loss: 0.2632 - val_accuracy: 0.8769\n",
            "Epoch 79/100\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.2912 - accuracy: 0.8698 - val_loss: 0.2586 - val_accuracy: 0.8814\n",
            "Epoch 80/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2900 - accuracy: 0.8640 - val_loss: 0.2557 - val_accuracy: 0.8831\n",
            "Epoch 81/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2848 - accuracy: 0.8715 - val_loss: 0.2588 - val_accuracy: 0.8836\n",
            "Epoch 82/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2827 - accuracy: 0.8691 - val_loss: 0.2564 - val_accuracy: 0.8827\n",
            "Epoch 83/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2793 - accuracy: 0.8711 - val_loss: 0.2594 - val_accuracy: 0.8806\n",
            "Epoch 84/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2904 - accuracy: 0.8666 - val_loss: 0.2519 - val_accuracy: 0.8875\n",
            "Epoch 85/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2892 - accuracy: 0.8641 - val_loss: 0.2527 - val_accuracy: 0.8860\n",
            "Epoch 86/100\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 0.2846 - accuracy: 0.8654 - val_loss: 0.2532 - val_accuracy: 0.8846\n",
            "Epoch 87/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2841 - accuracy: 0.8715 - val_loss: 0.2568 - val_accuracy: 0.8808\n",
            "Epoch 88/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2926 - accuracy: 0.8655 - val_loss: 0.2519 - val_accuracy: 0.8854\n",
            "Epoch 89/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2804 - accuracy: 0.8703 - val_loss: 0.2514 - val_accuracy: 0.8831\n",
            "Epoch 90/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2858 - accuracy: 0.8653 - val_loss: 0.2498 - val_accuracy: 0.8881\n",
            "Epoch 91/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2955 - accuracy: 0.8671 - val_loss: 0.2547 - val_accuracy: 0.8831\n",
            "Epoch 92/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2813 - accuracy: 0.8692 - val_loss: 0.2496 - val_accuracy: 0.8836\n",
            "Epoch 93/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2889 - accuracy: 0.8666 - val_loss: 0.2519 - val_accuracy: 0.8860\n",
            "Epoch 94/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2836 - accuracy: 0.8700 - val_loss: 0.2479 - val_accuracy: 0.8886\n",
            "Epoch 95/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2858 - accuracy: 0.8695 - val_loss: 0.2464 - val_accuracy: 0.8895\n",
            "Epoch 96/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2869 - accuracy: 0.8711 - val_loss: 0.2414 - val_accuracy: 0.8886\n",
            "Epoch 97/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2740 - accuracy: 0.8767 - val_loss: 0.2526 - val_accuracy: 0.8783\n",
            "Epoch 98/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2848 - accuracy: 0.8699 - val_loss: 0.2428 - val_accuracy: 0.8885\n",
            "Epoch 99/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2857 - accuracy: 0.8688 - val_loss: 0.2436 - val_accuracy: 0.8897\n",
            "Epoch 100/100\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2855 - accuracy: 0.8703 - val_loss: 0.2405 - val_accuracy: 0.8898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKZTJoIvb3l6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBQ7CkfsJiHZ"
      },
      "source": [
        "model.save('Epoch100.h5')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzPa3FIVbqN2"
      },
      "source": [
        "predicted=model.predict([inputs_test,queries_test])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a9J-9XYfDmM",
        "outputId": "0e397e94-3270-4abe-f501-50585b4c74db"
      },
      "source": [
        "predicted.shape "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CldSHYSGmqoR",
        "outputId": "0469cdd1-f880-471e-a1ce-64553597b5a3"
      },
      "source": [
        "test_data[0][0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'journeyed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeC1e7m5nGI8",
        "outputId": "823e6e22-b02a-49bb-81d1-a19ebd40ddfc"
      },
      "source": [
        "test_data[0][1]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'Sandra', 'in', 'the', 'hallway', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cYunvyLLnJCb",
        "outputId": "9cf2e5c0-7514-4406-865c-4ce80361342a"
      },
      "source": [
        "test_data[0][2]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjWLZ2Qumujv",
        "outputId": "c5cb807c-ebcd-44b1-a182-39752b3cafcf"
      },
      "source": [
        "predicted[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.53399460e-10, 1.43680595e-10, 1.02657063e-10, 8.23168964e-11,\n",
              "       1.37666989e-10, 7.51098073e-11, 1.30027364e-10, 1.49136550e-10,\n",
              "       8.54901358e-11, 8.11540696e-11, 1.56708979e-10, 2.00234759e-10,\n",
              "       1.39040515e-10, 9.99991298e-01, 2.07058357e-10, 1.45635143e-10,\n",
              "       9.12803583e-11, 6.98734334e-11, 8.79176801e-11, 9.65098834e-11,\n",
              "       9.59941987e-11, 1.04757696e-10, 8.31104421e-11, 7.97603789e-11,\n",
              "       8.74861507e-06, 9.90020912e-11, 9.82728829e-11, 9.70801772e-11,\n",
              "       8.83144877e-11, 2.08386405e-10, 1.32151859e-10, 6.89543561e-11,\n",
              "       1.05637533e-10, 7.91458774e-11, 1.30083430e-10, 1.03530511e-10,\n",
              "       1.06115734e-10, 1.44493792e-10], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DkQbp8jm-FE"
      },
      "source": [
        "val_max=np.argmax(predicted[0])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFFPNPHOnEiy",
        "outputId": "01eab648-2dc0-4b6d-aad3-0fc8eae1969c"
      },
      "source": [
        "for key ,val in tknizer.word_index.items():\r\n",
        "  if val==val_max:\r\n",
        "    print(key)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H01pBxTRncqC",
        "outputId": "7a0eb064-7b88-4396-f6c2-9c4c78143282"
      },
      "source": [
        "predicted[0][val_max]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXsmAYqyngeL"
      },
      "source": [
        "my_story='John left the kitchen . Sandra dropped the football in the garden .'  #Testing from a vocabset fixed on the training set \r\n",
        "my_story.split()\r\n",
        "my_question='Is the football in the garden ?'\r\n",
        "my_question.split()\r\n",
        "\r\n",
        "my_data=[(my_story.split(),my_question.split(),'yes')]\r\n",
        "\r\n",
        "my_story,my_ques,my_ans=vectorize_stories((my_data))\r\n",
        "\r\n",
        "pred_mys=model.predict([my_story,my_ques])\r\n",
        "val_max=np.argmax(pred_mys[0])\r\n",
        "\r\n",
        "for k,v in tknizer.word_index.items():\r\n",
        "    if v==val_max:\r\n",
        "        print(k)\r\n",
        "       \r\n",
        "print(z) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}